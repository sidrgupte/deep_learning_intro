{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "24. Transfer Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1gLvxOQT3niNvYFnq9ftl_ZuLAYmntEaz",
      "authorship_tag": "ABX9TyOnojHJLoHaUUz8tOzEEfxu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thelostwolf93/deep_learning_intro/blob/main/24_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVn3vkVrlSsm"
      },
      "source": [
        "# VGG16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_m3d-3dStcTn"
      },
      "source": [
        "## Initial Checks and Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQ8ZH72LlQg-",
        "outputId": "866c104c-88fd-4aab-eccb-54a902174c91"
      },
      "source": [
        "# checking the availability of GPU:\r\n",
        "import tensorflow as tf\r\n",
        "if tf.test.gpu_device_name():\r\n",
        "  print(f\"Default GPU Device {tf.test.gpu_device_name()}\")\r\n",
        "else:\r\n",
        "  print(\"Please install the GPU version of TF!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Default GPU Device /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnsWL5KWq2P6",
        "outputId": "043bd760-3bb5-473c-eede-00afedf648f8"
      },
      "source": [
        "# checking the version of GPU:\r\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Mar  1 08:02:11 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    24W /  75W |    201MiB /  7611MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8zsCXCBWsIg4",
        "outputId": "c666d668-b0a0-4ccf-8760-6b0ff5ce7103"
      },
      "source": [
        "# checking the version of tensorflow:\r\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YaNWN5XpxuK"
      },
      "source": [
        "# importing the required libraries:\r\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\r\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\r\n",
        "from tensorflow.keras.preprocessing import image \r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from glob import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfua8V_rtgeN"
      },
      "source": [
        "## Importing and Manipulating the Built Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iV4SFYgJtaX6"
      },
      "source": [
        "# re-size all the images to 224*224 because that is the standard size used for VGG\r\n",
        "IMAGE_SIZE = [224,224]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W90lSvzOtu-L"
      },
      "source": [
        "# training and validation set paths:\r\n",
        "train_path = \"/content/drive/MyDrive/datasets/Cats and Dogs/train\"\r\n",
        "valid_path  = \"/content/drive/MyDrive/datasets/Cats and Dogs/test\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2qAjJzkt7c9",
        "outputId": "0c4d477b-8898-4ce8-8b36-2d7e8b43b976"
      },
      "source": [
        "# Importing the VGG16 library + Adding preprocessing layers in the beginning of VGG16\r\n",
        "vgg16 = VGG16(input_shape = IMAGE_SIZE + [3],\r\n",
        "              weights     = \"imagenet\",\r\n",
        "              include_top = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2K96Fe92_XkJ",
        "outputId": "569dd098-5769-4800-c8e8-4a6a838fc3a6"
      },
      "source": [
        "vgg16.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W01QYvVI_mrl"
      },
      "source": [
        "# we don't want to train the existing weights: \r\n",
        "for layer in vgg16.layers:\r\n",
        "  layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9w_K-g8ATN1",
        "outputId": "d9eb8834-0d82-4035-fbf8-ca5f410ad720"
      },
      "source": [
        "# to get the total number of categories:\r\n",
        "folders = glob(\"/content/drive/MyDrive/datasets/Cats and Dogs/train/*\")\r\n",
        "num_output = len(folders)\r\n",
        "print(f\"The number of categories in the train folder is {num_output}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of categories in the train folder is 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSrvLxgSCNZj"
      },
      "source": [
        "# the next layer after VGG16 layer is the flattened layer:\r\n",
        "x = Flatten()(vgg16.output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5J0mGDrCQtE"
      },
      "source": [
        "# now we create the output later which will have 2 categories and will give us the prediction:\r\n",
        "prediction = Dense(num_output, activation = \"softmax\")(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJrJsImnDMSV"
      },
      "source": [
        "# create a model object:\r\n",
        "model = Model(inputs=vgg16.input, outputs = prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tuvg9jL9DTaa",
        "outputId": "2f6112b4-a492-4b5c-b13b-daa1b3bd5ff5"
      },
      "source": [
        "# viewing the structure of the model\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 50178     \n",
            "=================================================================\n",
            "Total params: 14,764,866\n",
            "Trainable params: 50,178\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKQIBzLRDjjq"
      },
      "source": [
        "  # specifying the cost and optimization method\r\n",
        "  model.compile( loss     = \"categorical_crossentropy\",\r\n",
        "                optimizer = \"adam\",\r\n",
        "                metrics   = [\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avrtPL7lEz5s"
      },
      "source": [
        "## Training on the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7DHfGFWEuKB"
      },
      "source": [
        "# using the Image Data Generator, we import the images from the dataset:\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "# Data Augmentation:\r\n",
        "train_datagen = ImageDataGenerator(rescale         = 1./255,\r\n",
        "                                   shear_range     = 0.2,\r\n",
        "                                   zoom_range      = 0.2,\r\n",
        "                                   horizontal_flip = True)\r\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hN5VWBFhFUHt",
        "outputId": "08ee78b7-6997-459f-c3a6-dd706c66a70e"
      },
      "source": [
        "training_set = train_datagen.flow_from_directory(\"/content/drive/MyDrive/datasets/Cats and Dogs/train\",\r\n",
        "                                                 target_size = (224,224),\r\n",
        "                                                 batch_size  = 32,\r\n",
        "                                                 class_mode  = \"categorical\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9b8w3RO5jqU",
        "outputId": "ae0fab42-ffee-4a81-99e2-46e48d61f935"
      },
      "source": [
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/datasets/Cats and Dogs/test',\r\n",
        "                                            target_size = (224, 224),\r\n",
        "                                            batch_size = 32,\r\n",
        "                                            class_mode = 'categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOZ_bDv1GIG_",
        "outputId": "5e8369d4-bbc2-4967-b10e-f669ff4ffd86"
      },
      "source": [
        "# fitting the model:\r\n",
        "r = model.fit_generator(\r\n",
        "    training_set,\r\n",
        "    validation_data = test_set,\r\n",
        "    epochs = 20,\r\n",
        "    steps_per_epoch = len(training_set),\r\n",
        "    validation_steps = len(test_set)\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "  2/250 [..............................] - ETA: 27:59 - loss: 0.6555 - accuracy: 0.6484  "
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-5788926c8183>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "p70LdzhaSmmy",
        "outputId": "2e258500-fbf2-437f-ad1e-f0155a132d25"
      },
      "source": [
        "# Plotting the Loss\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "plt.plot(r.history[\"loss\"], label=\"train loss\")\r\n",
        "plt.plot(r.history[\"val_loss\"], label=\"val loss\")\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OURaN20IsyLz"
      },
      "source": [
        "# Plotting the accuracy \r\n",
        "plt.plot(r.history[\"accuracy\"], label=\"training acc\")\r\n",
        "plt.plot(r.history[\"val_accuracy\"], label=\"val acc\")\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRSenY-sSwfb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}